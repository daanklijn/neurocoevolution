<html class="h-screen">
<head>
    <link href="https://unpkg.com/tailwindcss@^2/dist/tailwind.min.css" rel="stylesheet">
</head>
<body>
<div class="w-full p-8">
    <div class="text-2xl font-serif text-center">A Coevolutionary Approach to Deep Multi-agent Reinforcement Learning</div>
    <div class="text-xl font-serif text-center">Daan Klijn and Gusz Eiben</div>
</div>
<div class="grid grid-rows-2 grid-cols-3 grid-flow-row gap-6 p-6">
    <div class="row-span-2 col-span-1 bg-white p-8">
        <div class="text-bg font-bold">Problem statement and contributions</div>
        <div class="text-sm">
            Recent research shows that Deep Neuroevolution is capable of evolving multi-million-parameter DNN's, which proved to be particularly useful in the field of Reinforcement Learning (RL).
            This is mainly due to its excellent scalability and simplicity compared to the traditional MDP-based RL methods.
            <br>
            <br>
            So far, Deep Neuroevolution has only been applied to complex single-agent problems. As evolutionary methods are a natural choice for multi-agent problems, the following question arises: <span class="font-bold">can Deep Neuroevolution can also be applied in a complex multi-agent setting?</span>
            <br>
            <br>
            In this work, we describe and validate <span class="font-bold">a new approach based on coevolution</span>. To validate our approach, we benchmark two Deep coevolutionary Algorithms on a range of multi-agent Atari games and compare our results against the results of Ape-X DQN.
            <br>
            <br>
            Our research shows that the combination of Deep Neuroevolution and Coevolution:
            <ul class="list-disc pl-6">
                <li>Can succesfully learn to play multiplayer video games using pixel inputs.</li>
                <li>Outperforms Ape-X DQN in some of the benchmarks.</li>
                <li>Are a viable approach to solving complex multi-agent decision-making problems.</li>
                <li>Might open up a new door in the field of MARL.</li>
            </ul>
        </div>
    </div>
    <div class="col-span-1 bg-white p-8">
        <div class="text-bg font-bold">Our approach</div>
        <div class="text-xs">
            Traditionally, Deep Artificial Neural Networks (DNN's) are trained through gradient descent. Recent research shows that Deep Neuroevolution (DNE) is also capable of evolving multi-million-parameter DNN's, which proved to be particularly useful in the field of Reinforcement Learning (RL). This is mainly due to its excellent scalability and simplicity compared to the traditional MDP-based RL methods. So far, DNE has only been applied to complex single-agent problems. As evolutionary methods are a natural choice for multi-agent problems, the question arises whether DNE can also be applied in a complex multi-agent setting. In this paper, we describe and validate a new approach based on coevolution. To validate our approach, we benchmark two Deep coevolutionary Algorithms on a range of multi-agent Atari games and compare our results against the results of Ape-X DQN. Our results show that these Deep coevolutionary algorithms (1) can be successfully trained to play various games, (2) outperform Ape-X DQN in some of them, and therefore (3) show that coevolution can be a viable approach to solving complex multi-agent decision-making problems.
        </div>
    </div>
    <div class="row-span-1 col-span-1 bg-white p-8">
        <div class="text-bg font-bold">Experiments</div>
        <div class="text-xs">
            Traditionally, Deep Artificial Neural Networks (DNN's) are trained through gradient descent. Recent research shows that Deep Neuroevolution (DNE) is also capable of evolving multi-million-parameter DNN's, which proved to be particularly useful in the field of Reinforcement Learning (RL). This is mainly due to its excellent scalability and simplicity compared to the traditional MDP-based RL methods. So far, DNE has only been applied to complex single-agent problems. As evolutionary methods are a natural choice for multi-agent problems, the question arises whether DNE can also be applied in a complex multi-agent setting. In this paper, we describe and validate a new approach based on coevolution. To validate our approach, we benchmark two Deep coevolutionary Algorithms on a range of multi-agent Atari games and compare our results against the results of Ape-X DQN. Our results show that these Deep coevolutionary algorithms (1) can be successfully trained to play various games, (2) outperform Ape-X DQN in some of them, and therefore (3) show that coevolution can be a viable approach to solving complex multi-agent decision-making problems.
        </div>
    </div>
    <div class="row-span-1 col-span-1 bg-white p-8">
        <div class="text-bg font-bold">Results</div>
        <div class="text-xs">
            Traditionally, Deep Artificial Neural Networks (DNN's) are trained through gradient descent. Recent research shows that Deep Neuroevolution (DNE) is also capable of evolving multi-million-parameter DNN's, which proved to be particularly useful in the field of Reinforcement Learning (RL). This is mainly due to its excellent scalability and simplicity compared to the traditional MDP-based RL methods. So far, DNE has only been applied to complex single-agent problems. As evolutionary methods are a natural choice for multi-agent problems, the question arises whether DNE can also be applied in a complex multi-agent setting. In this paper, we describe and validate a new approach based on coevolution. To validate our approach, we benchmark two Deep coevolutionary Algorithms on a range of multi-agent Atari games and compare our results against the results of Ape-X DQN. Our results show that these Deep coevolutionary algorithms (1) can be successfully trained to play various games, (2) outperform Ape-X DQN in some of them, and therefore (3) show that coevolution can be a viable approach to solving complex multi-agent decision-making problems.
        </div>
    </div>
    <div class="row-span-1 col-span-1 bg-white p-8">
        <div class="text-bg font-bold">Conclusion</div>
        <div class="text-xs">
            Traditionally, Deep Artificial Neural Networks (DNN's) are trained through gradient descent. Recent research shows that Deep Neuroevolution (DNE) is also capable of evolving multi-million-parameter DNN's, which proved to be particularly useful in the field of Reinforcement Learning (RL). This is mainly due to its excellent scalability and simplicity compared to the traditional MDP-based RL methods. So far, DNE has only been applied to complex single-agent problems. As evolutionary methods are a natural choice for multi-agent problems, the question arises whether DNE can also be applied in a complex multi-agent setting. In this paper, we describe and validate a new approach based on coevolution. To validate our approach, we benchmark two Deep coevolutionary Algorithms on a range of multi-agent Atari games and compare our results against the results of Ape-X DQN. Our results show that these Deep coevolutionary algorithms (1) can be successfully trained to play various games, (2) outperform Ape-X DQN in some of them, and therefore (3) show that coevolution can be a viable approach to solving complex multi-agent decision-making problems.
        </div>
    </div>
</div>
<!--    <div class="bg-white p-8 mb-6 rounded shadow-md">Algorithm</div>-->
<!--    <div class="bg-white p-8 mb-6 rounded shadow-md">Experiments</div>-->
<!--    <div class="bg-white p-8 mb-6 rounded shadow-md">Results</div>-->
<!--    <div class="bg-white p-8 mb-6 rounded shadow-md">Conclusion</div>-->
</div>

</body>
</html>
<style>
    .masonry-3 {
        column-count: 3;
        column-gap: 1.5em;
    }
</style>
